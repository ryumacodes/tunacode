"""Characterization tests for edge cases across file, git, and token utilities."""

import pytest
import sys
from tunacode.utils import file_utils, token_counter

def test_dotdict_non_string_keys():
    d = file_utils.DotDict({1: "one"})
    assert d[1] == "one"
    d[2] = "two"
    assert d[2] == "two"

def test_dotdict_nested_access():
    d = file_utils.DotDict({"outer": file_utils.DotDict({"inner": 42})})
    assert d.outer.inner == 42

def test_capture_stdout_with_exception():
    original_stdout = sys.stdout
    try:
        with file_utils.capture_stdout() as out:
            print("before error")
            raise ValueError("fail!")
    except ValueError:
        pass
    # Current behavior: stdout is restored to what it was before capture
    assert sys.stdout is original_stdout

@pytest.mark.parametrize("text,expected", [
    ("ä½ å¥½ä¸–ç•Œ", 1),  # 4 Chinese chars, still 1 token by naive logic
    ("ðŸ˜€" * 8, 2),   # 8 emoji, each is a multi-byte char
])
def test_estimate_tokens_unicode(text, expected):
    assert token_counter.estimate_tokens(text) == expected

def test_format_token_count_negative():
    # Current behavior: no comma formatting for negative numbers
    assert token_counter.format_token_count(-1000) == "-1000"

def test_format_token_count_large():
    assert token_counter.format_token_count(10**9) == "1,000,000,000"